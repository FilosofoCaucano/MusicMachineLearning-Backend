{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias necesarias  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow tensorflow-hub librosa numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando Constantes con las direcciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URLs de los modelos\n",
    "YAMNET_MODEL_URL = \"https://tfhub.dev/google/yamnet/1\"\n",
    "VGGISH_MODEL_URL = \"https://tfhub.dev/google/vggish/1\"\n",
    "\n",
    "# Nombre del archivo de audio local\n",
    "AUDIO_FILE = \"guitar-01.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índices de las clases de guitarra en YAMNet : URL : https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv\n",
    "GUITAR_CLASSES = [132, 425]  # Acoustic guitar, Electric guitar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando las funciones para reusar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar el audio y convertirlo a la frecuencia de muestreo necesaria\n",
    "def load_audio_file(file_path, target_sample_rate=16000):\n",
    "    audio, sr = librosa.load(file_path, sr=target_sample_rate)\n",
    "    # Normalizar el audio entre -1 y 1\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio, sr\n",
    "\n",
    "# Cargar el modelo de YAMNet\n",
    "def load_yamnet_model():\n",
    "    yamnet_model = hub.load(YAMNET_MODEL_URL)\n",
    "    return yamnet_model\n",
    "\n",
    "# Cargar el modelo de VGGish\n",
    "def load_vggish_model():\n",
    "    vggish_model = hub.load(VGGISH_MODEL_URL)\n",
    "    return vggish_model\n",
    "\n",
    "# Realizar la predicción con YAMNet\n",
    "def predict_yamnet(yamnet_model, audio_data):\n",
    "    # Asegurarse de que el audio sea un tensor de float32\n",
    "    audio_tensor = tf.convert_to_tensor(audio_data, dtype=tf.float32)\n",
    "    scores, embeddings, spectrogram = yamnet_model(audio_tensor)\n",
    "    predicted_class = tf.argmax(scores, axis=-1)\n",
    "    return predicted_class.numpy(), scores.numpy()\n",
    "\n",
    "# Realizar la predicción con VGGish\n",
    "def predict_vggish(vggish_model, audio_data):\n",
    "    # VGGish solo necesita embeddings, por lo que no se necesita predicción directa\n",
    "    audio_tensor = tf.convert_to_tensor(audio_data, dtype=tf.float32)\n",
    "    embeddings = vggish_model(audio_tensor)\n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar el audio para la entrada del modelo\n",
    "audio_data, sample_rate = load_audio_file(AUDIO_FILE)\n",
    "\n",
    "# Cargar modelos\n",
    "yamnet_model = load_yamnet_model()\n",
    "vggish_model = load_vggish_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAMNet - Predicted Class: [132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132\n",
      " 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132\n",
      " 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132\n",
      " 132 132 132 132 132 132 132 132 132 132]\n",
      "YAMNet - Scores Shape: (64, 521)\n",
      "VGGish - Embeddings Shape: (32, 128)\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones con YAMNet\n",
    "yamnet_pred_class, yamnet_scores = predict_yamnet(yamnet_model, audio_data)\n",
    "\n",
    "# Realizar predicciones con VGGish (usando la misma entrada)\n",
    "vggish_embeddings = predict_vggish(vggish_model, audio_data)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"YAMNet - Predicted Class:\", yamnet_pred_class)\n",
    "print(\"YAMNet - Scores Shape:\", yamnet_scores.shape)\n",
    "print(\"VGGish - Embeddings Shape:\", vggish_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGish - Embeddings Shape: [[-0.7336062  -0.18590459  0.39883107 ... -0.85758007 -0.07540295\n",
      "  -0.2769341 ]\n",
      " [-1.085657   -0.51505184  0.36990386 ... -1.0317211   0.16072503\n",
      "  -0.17959717]\n",
      " [-0.88073695 -0.49706617  0.00116414 ... -0.7746079  -0.19385038\n",
      "  -0.34082073]\n",
      " ...\n",
      " [-0.5604361  -0.36990973  0.15180324 ... -0.7322267  -0.1039039\n",
      "  -0.21786481]\n",
      " [-0.9799707  -0.4949585   0.21475768 ... -1.1171416  -0.18682863\n",
      "  -0.33782995]\n",
      " [-0.79963374 -0.43110666  0.2771427  ... -0.95338655 -0.28829026\n",
      "  -0.30207974]]\n"
     ]
    }
   ],
   "source": [
    "print(\"VGGish - Embeddings Shape:\", vggish_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El audio contiene una guitarra.\n"
     ]
    }
   ],
   "source": [
    "# Identificar si alguna de las clases predichas es una guitarra\n",
    "is_guitar = any(cls in GUITAR_CLASSES for cls in yamnet_pred_class)\n",
    "\n",
    "# Mostrar resultados\n",
    "if is_guitar:\n",
    "    print(\"El audio contiene una guitarra.\")\n",
    "else:\n",
    "    print(\"El audio no contiene una guitarra.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
